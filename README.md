# Gender-Bias-in-VLM--Reasoning-using-COT
We propose an explainable system for detecting gender bias in vision-language models (VLMs) using real-world image-caption pairs and step-by-step reasoning. GPT-4 generates chain-of-thought justifications, and LLaMA-V-O1 is fine-tuned on structured reasoning data. This method offers rationale-backed decisions, ensuring ethical AI transparency.
